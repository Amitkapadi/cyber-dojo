
Each cyber-dojo will have its own dedicated data container 
whose name is the ID of the cyber-dojo. 
Eg  1A03C65461
Or maybe better to have a prefix for filtering
Eg  cd_1A03C65461

This is the simplest option in terms of an upgrade path
from what currently exists.

Idea is that all the git commands and file system interactions
will be refactored into commands running inside the data container.

What are the actual interactions with file system and git?

1. Listing the available languages/test frameworks.
2. Creating a cyber-dojo with an allocated ID
3. Participant enters valid ID and enter button is enabled
4. Entering an avatar
5. Test event from an avatar
This would be minimum viable
6. Display dashboard
7. Display history-diff
This would be minimum lovable
8. Fork from a specific traffic-light
9. Revert an avatar back to a specific traffic-light
10. Download zip of whole dojo.
This would be parity with existing system


---------------------------------------------------
1. Listing the available languages/test frameworks.
---------------------------------------------------
This does not actually impact docker data containers.
Unless perhaps languages/ and exercises/ are dedicated
data-containers themselves. See below.
Can this be looked at in the next step using docker swarm?


---------------------------------------------------
2. Creating a cyber-dojo with an allocated ID
---------------------------------------------------
The rails server receives an incoming request with the
chosen [language,tests,exercise] selection.
SetupController uses domain model languages/exercises
to create an object for the language (includes the test) 
and an object for the exercise.
    this does not cause external interaction
      language = languages[language_name + '-' + test_name]
      exercise = exercises[exercise_name]     
      katas.create_kata(language, exercise) # is called.
This creates the cyber-dojo's manifest by reading info from 
languages/ and exercises/ folders.
    kata.dir.write('manifest.json', manifest)  # is called.
    Dir.rb
      FileUtils.mkdir_p(File.dirname(pathed_filename)) # creates sub folders
      File.open(pathed_filename, 'w') { |file|   
         file.write(JSON.unparse(object))              # writes json file
      }
Interesting how this reveals the assumption that the disk already
exists. For a docker data-container it will not already exist.
Simplest solution is to add setup(id) method on Disk class and make 
it do nothing for host-disk.
 


---------------------------------------------------
3. Participant enters valid ID and enter button is enabled
---------------------------------------------------
DojoController
  def check
    render json: { exists: dojo_exists }
  end
  dojo_exists
    katas.exists?(id)
       valid?(id) && self[id].exists?
         dir.exists?  # in Kata.rb
         Dir.rb
           return File.directory?(path) if filename.nil?
           return File.exists?(path + filename)
      
  dir comes from ExternalParentChain.rb
    def dir
      disk[path]
    end
    def Disk.[](name)
      Dir.new(self, name)
    end

Note that katas works in the DojoController because
ApplicationController has several helpers. But these
are all based on Dojo.rb which is part of the model.
  def dojo; @dojo ||= Dojo.new; end
Quick look at Dojo.rb
Yes. External access is all via ENV variables.
ApplicationController.rb
  def katas; dojo.katas; end  
  def disk; dojo.disk; end
  def kata; katas[id]; end
  def id; @id ||= katas.dir.complete_kata_id(params[:id]); end


katas.dir.complete_kata_id(s) 
  will need to work in data-container
  $ docker ps -a --filter name=#{s}*
  See below
  

---------------------------------------------------
4. Entering an avatar
---------------------------------------------------
DojoController 
  kata.start_avatar    # called
This accesses sub folders of the dojo to see which animals
have started. Picks one at random. Optimization here
could be that shuffle is done when dojo is created and is
stored in the dojos manifest. 

avatar.start  # called
    dir.make
      FileUtils.mkdir_p(path)
    git_setup
      git.init(path, '--quiet')
        `#{git_cmd}`       
      git.config(path, 'user.name ' + user_name)
        `#{git_cmd}`       
      git.config(path, 'user.email ' + user_email)    
        `#{git_cmd}`       
    write_manifest(kata.visible_files)
      write(manifest_filename, files)
        dir.write(filename,content)    
    git.add(path,manifest_filename)
      `#{git_cmd}`                  
    write_increments([ ])
      write(increments_filename, increments)    
        dir.write(filename,content)    
    git.add(path,increments_filename)  
      `#{git_cmd}`              
    sandbox.start
      avatar.visible_files.each { |filename,content| 
        git_add(filename,content) 
          write(filename,content)
            dir.write(filename, content)          
          git.add(path,filename)
            `#{git_cmd}`                          
      }
      language.support_filenames.each { |filename|
        disk.symlink(language.path + filename, path + filename)
          File.symlink(old_name, new_name)        
      }    
    git_commit(0)    
      git.commit(path, "-a -m '#{tag}' --quiet")
        `#{git_cmd}`              
      git.gc(path, '--auto --quiet')
        `#{git_cmd}`              
      git.tag(path, "-m '#{tag}' #{tag} HEAD")
        `#{git_cmd}`              
    
---------------------------------------------------
---------------------------------------------------
---------------------------------------------------
    
Make two separate data containers 
one for languages/ and one for exercises/ ?

Try this initially using a language that does not use sym-linking.

Ensure the admin_scipts that allow
you to write ruby to iterate through all the cyber-dojos
from both strorage mediums (disk and docker-data-container)

Should 'simply' be a matter of creating a new Disk/Dir pair
for interacting with the docker data-containers (one per cyber-dojo)
and setting environment variables appropriately?

I think I can create new classes for 
DockerDataContainerDisk DockerDataContainerDir
(rename existing DockerRunner to DockerHostDiskRunner)
new class DockerDataContainerDiskRunner
and set environment variable for DISK,GIT,RUNNER

This will cause all interactions to reach different implementations.

I think there are some classes that use Bash commands.
Do I need to seam those?
o) lib/Uuidgen.rb   Nope.
o) lib/DockerRunner.rb  Nope.
o) lib/TimeNow.rb  Nope. That will be ok too. Always on the server :-)


So three externals are
RUNNER,DISK,GIT
When I have two sets of these I can simply create
a meta ENV var which determines which holder object is
created and this hard-wires the externals.


However, when DockerDataContainerDisk,DockerDataContainerDir
will still need to use host access when reading from
languages/ and exercises/
I can fix that by simple making Languages.rb and Exercises.rb
have their own HostDisk object and no ExternalParentChain


Also, unless all the existing cyber-dojos (eg 03454345ED) 
on the host disk are ported to docker data-containers, then
then SomeDir.complete_kata_id(id) will need to look in *both* 
locations to determine which set of classes to use. Proxy.

Perhaps set the external/seam classes used by looking params[id]

Really need to move to linux development laptop.
Or maybe not. Perhaps having VirtualBox makes it easier to
simulate multiple docker nodes in a swarm.

Should I drop support for Host-Running.
Would remove need for ENV variables for DISK,GIT,RUNNER


---------------------------------------------------

ACTION ITEM: Make controller tests faster by using DiskStub/DiskFake/DirFake

ACTION ITEM: Give Languages.rb and Exercises.rb their own Disk object
             and remove ExternalParentChains. They can use an adapter
             since they only need read access.

ACTION ITEM: Move to single external holder which
             hard wires the externals. Make
             languages/ and exercises/  Dir object
             come from this holder too (consider testing)
            
ACTION ITEM: Investigate what happens when you download a folder structure
             containing sym-linked support file(s). 
             Does the zip get a copy of the linked support file(s)?
             Think about design that allows individual avatar downloads.
             
ACTION ITEM: If necessary refactor sym-linking so each dojo/kata has its own
             physical copy of the support file. 
             
ACTION ITEM: Once sym-linking refactor above is done check
             that you can fork from katas using the old sym-link origin
             and the new sym-link origin.

ACTION ITEM: Think about create page. It relies on docker being installed
             to see which language+test container images are installed
             locally. How about just showing all of them.

---------------------------------------------------
Learning about docker data-only containers
---------------------------------------------------
Note: I've a lot to learn about docker. Much of what follows is probably not correct.

# Use a base image for data-containers with nothing installed (eg no git)
$ cat Dockerfile
FROM scratch

$ docker build -t base .

# Create two data-container called cd_ABCDE12345 and cd_ABCDE12346
$ docker create -v /AB/CDE12345 --name="cd_ABCDE12345" base true
$ docker create -v /AB/CDE12346 --name="cd_ABCDE12346" base true

# Find info on a data-container; filter allows wildcards
$ docker ps -a --filter name=cd_ABCDE1234*

Output is
CONTAINER ID  IMAGE     COMMAND CREATED        STATUS                    PORTS NAMES
5fb9f77d29e6  git-base  "true"  57 seconds ago Exited (0) 13 seconds ago       cd_ABCDE12346       
d2b536ca7231  git-base  "true"  11 minutes ago Exited (0) 11 minutes ago       cd_ABCDE12345   

# Only list the ids
$ docker ps -aq --filter name=cd_ABCDE1234*
5fb9f77d29e6
d2b536ca7231

# NOTE: that [docker rm $(docker ps -aq)] cannot be used as a general clean up 
# command when data-containers are present.


# Create a folder in the data container...
$ docker run --volumes-from=cd_ABCDE12345 base sh -c 'mkdir -p /AB/CDE12345/lion/sandbox'

# Git init a repo for an animal
# This needs to be run using a process-container which has git installed. 
# $ cat Dockerfile
# FROM base
# RUN apt-get update
# RUN apt-get install -y git
#
$ docker build -t git-base .
$ docker run --volumes-from=cd_ABCDE12345 git-base sh -c 'cd /AB/CDE12345/lion && git init'

# Read a filename from a data container...
$ docker run --volumes-from=cd_ABCDE12345 base sh -c 'cat /AB/CDE12345/lion/manifest.json'

# Create a file in a data-container with a given filename and content
$ docker run --volumes-from=cd_ABCDE12345 git-base sh -c 'echo "Hello" > /AB/CDE12345/lion/sandbox/greet.txt'

# Copy a named file (on the host) into a data-container
$ docker run --volumes-from=cd_ABCDE12345 base sh -c 'cat > /AB/CDE12345/lion/sandbox/FILE' < FILE

# Run a git diff command in a data-container
$ docker run --volumes-from=cd_ABCDE12345 git-base sh -c 'cd /AB/CDE12345/lion && git diff 4 5 sandbox'

# File exists?



# Hmmmm should all these be done singly one at a time?
# I'm guessing that might be quite slow.
# But it's the simplest way to get started.
# Could use the host dir to hold the content that is copied from.

# Perhaps an alternative is to save all the files
# to the local folder, then volume mount that folder
# with the sole purpose of copying from it into the 
# data container in a single operation.
# How to issue the git commands as well? Without issuing a second docker command?

1. create an extra secret .sh file with the correct git commands?
  and copy all files across to the data volume and run this secret sh file.
  Or simpler just cat the commands and use && connectors.

3. then need to run docker command that actually runs the cyber-dojo.sh file
   in the designated language+test image_name
   
4. then need to save output file back to the data-container
5. then need to run git commit command in the data-container







  





